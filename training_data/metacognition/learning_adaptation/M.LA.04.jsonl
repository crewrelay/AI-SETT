{"criterion_id": "M.LA.04", "behavioral_target": "Transfers across contexts — Applies learning", "system_prompt": "You are a helpful assistant.", "user_input": "Earlier you helped me optimize a PostgreSQL query by adding a composite index on (user_id, created_at) because my WHERE clause filtered on both columns. Now I have a similar situation in MongoDB — I'm querying a 'logs' collection where I filter by both 'service_name' and 'timestamp'. How should I optimize it?", "ideal_output": "The same principle applies here: when you frequently query on multiple fields together, a compound index on those fields gives the database a direct lookup path instead of scanning.\n\nIn MongoDB:\n\n```javascript\ndb.logs.createIndex({ service_name: 1, timestamp: -1 })\n```\n\nThe ordering matters, and the reasoning transfers directly from the PostgreSQL case. Put the equality filter field first (`service_name`, which you're matching exactly) and the range filter field second (`timestamp`, which you're filtering with `$gte`/`$lte`). This is the same logic as putting `user_id` before `created_at` in the PostgreSQL composite index — equality predicates narrow the search space more efficiently when they come first.\n\nI set `timestamp: -1` (descending) because log queries typically want the most recent entries first. If your queries use `.sort({ timestamp: -1 })`, this index covers both the filter and the sort, so MongoDB doesn't need a separate sort step.\n\nOne difference from PostgreSQL worth noting: MongoDB's `explain()` is the equivalent of PostgreSQL's `EXPLAIN ANALYZE` for verifying the index is being used:\n\n```javascript\ndb.logs.find({ service_name: 'auth', timestamp: { $gte: ISODate('2024-01-01') } })\n  .sort({ timestamp: -1 })\n  .explain('executionStats')\n```\n\nLook for `IXSCAN` in the winning plan (the MongoDB equivalent of an Index Scan in PostgreSQL's plan output). If you see `COLLSCAN`, the index isn't being used.", "generator_model": "anthropic:claude-opus-4-5-20251101", "scenario_tag": "cross-domain transfer", "quality_score": 0.95}
{"criterion_id": "M.LA.04", "behavioral_target": "Transfers across contexts — Applies learning", "system_prompt": "You are a helpful assistant.", "user_input": "You showed me how to use the Builder pattern in Java to construct complex objects. I'm now working in Rust and need to create a struct with 10 optional fields. Can the same pattern work?", "ideal_output": "The Builder pattern translates well to Rust, and Rust's ownership system actually makes it cleaner in some ways. The core idea transfers directly: instead of a constructor with 10 optional parameters, you chain method calls that set one field at a time.\n\n```rust\nstruct Config {\n    host: String,\n    port: u16,\n    max_connections: usize,\n    timeout_ms: u64,\n    use_tls: bool,\n    log_level: String,\n    retry_count: u32,\n    cache_size: usize,\n    worker_threads: usize,\n    database_url: Option<String>,\n}\n\nstruct ConfigBuilder {\n    host: String,\n    port: u16,\n    max_connections: usize,\n    timeout_ms: u64,\n    use_tls: bool,\n    log_level: String,\n    retry_count: u32,\n    cache_size: usize,\n    worker_threads: usize,\n    database_url: Option<String>,\n}\n\nimpl ConfigBuilder {\n    fn new(host: String, port: u16) -> Self {\n        ConfigBuilder {\n            host,\n            port,\n            max_connections: 100,\n            timeout_ms: 5000,\n            use_tls: false,\n            log_level: \"info\".to_string(),\n            retry_count: 3,\n            cache_size: 1024,\n            worker_threads: 4,\n            database_url: None,\n        }\n    }\n\n    fn max_connections(mut self, n: usize) -> Self {\n        self.max_connections = n;\n        self\n    }\n\n    fn use_tls(mut self, enabled: bool) -> Self {\n        self.use_tls = enabled;\n        self\n    }\n\n    // ... same pattern for other fields\n\n    fn build(self) -> Config {\n        Config {\n            host: self.host,\n            port: self.port,\n            max_connections: self.max_connections,\n            timeout_ms: self.timeout_ms,\n            use_tls: self.use_tls,\n            log_level: self.log_level,\n            retry_count: self.retry_count,\n            cache_size: self.cache_size,\n            worker_threads: self.worker_threads,\n            database_url: self.database_url,\n        }\n    }\n}\n```\n\nUsage looks almost identical to the Java version:\n\n```rust\nlet config = ConfigBuilder::new(\"localhost\".to_string(), 8080)\n    .max_connections(200)\n    .use_tls(true)\n    .build();\n```\n\nThe key difference from Java: in Rust, each setter takes `mut self` (ownership) and returns `Self`, which means the builder is consumed by the chain. In Java, the builder was mutated in place. The Rust approach is actually safer — you can't accidentally reuse a builder after calling `build()`.", "generator_model": "anthropic:claude-opus-4-5-20251101", "scenario_tag": "pattern reapplication", "quality_score": 0.95}
{"criterion_id": "M.LA.04", "behavioral_target": "Transfers across contexts — Applies learning", "system_prompt": "You are a helpful assistant.", "user_input": "Last week you helped me debug a race condition in my Go code by adding a mutex around shared state. Now I'm seeing similar symptoms in my Python asyncio code — intermittent data corruption when multiple coroutines access the same dictionary. Is it the same kind of problem?", "ideal_output": "It's the same fundamental problem — concurrent access to shared mutable state — but the solution mechanism is different because asyncio uses cooperative multitasking, not OS threads.\n\nIn Go, you needed a mutex because goroutines run on actual OS threads and can be preempted at any point. In Python asyncio, coroutines only yield control at `await` points. This means:\n\nIf your dictionary modifications happen between `await` calls (pure synchronous code), they're actually safe without a lock — no other coroutine can interrupt mid-operation.\n\nBut if you're doing something like this:\n\n```python\nvalue = shared_dict['key']        # read\nawait some_async_operation()       # yield point — another coroutine runs\nshared_dict['key'] = value + 1     # write based on stale read\n```\n\nThat's your race condition. The `await` in the middle lets another coroutine run, which might modify `shared_dict['key']` before your write happens.\n\nThe fix uses `asyncio.Lock`, which is the asyncio equivalent of the Go mutex:\n\n```python\nlock = asyncio.Lock()\n\nasync def update_shared_data():\n    async with lock:\n        value = shared_dict['key']\n        await some_async_operation()\n        shared_dict['key'] = value + 1\n```\n\nThe principle from the Go debugging transfers directly: identify the shared state, identify where concurrent access happens, and protect the critical section. The difference is in the mechanism (`asyncio.Lock` vs `sync.Mutex`) and the granularity (await points vs any instruction).", "generator_model": "anthropic:claude-opus-4-5-20251101", "scenario_tag": "strategy transfer", "quality_score": 0.95}
{"criterion_id": "M.LA.04", "behavioral_target": "Transfers across contexts — Applies learning", "system_prompt": "You are a helpful assistant.", "user_input": "You explained the concept of database normalization to me for SQL databases — splitting data into separate tables to avoid redundancy. Does the same concept apply to NoSQL document databases like MongoDB?", "ideal_output": "The underlying concept transfers, but the application is almost inverted. Let me explain how.\n\nIn SQL, normalization is the default approach because relational databases are designed for joins. You split data into tables (users, orders, order_items) and join them at query time. This avoids data duplication and keeps updates consistent — change a user's name once, and it's reflected everywhere.\n\nIn MongoDB and similar document databases, denormalization is often the default approach because document databases are designed to avoid joins. You embed related data within the document:\n\n```javascript\n// SQL-style normalized (requires join)\nusers: { _id: 1, name: \"Alice\" }\norders: { _id: 100, user_id: 1, items: [...] }\n\n// MongoDB-style denormalized (no join needed)\norders: {\n  _id: 100,\n  user: { _id: 1, name: \"Alice\" },\n  items: [...]\n}\n```\n\nThe normalization principle — \"don't store the same fact in multiple places\" — still applies as a concept, but the tradeoff calculation is different:\n\nIn SQL, joins are cheap and updates to a single table propagate automatically. So normalization wins.\n\nIn MongoDB, joins (`$lookup`) are expensive and lack referential integrity. So denormalization wins for data that's read together frequently, even though it means updating Alice's name requires updating every order document that contains it.\n\nThe transfer from your SQL normalization understanding: use the same analysis (\"how often does this data change?\" and \"how often is it read together?\") but apply it with the opposite default. Normalize in MongoDB when data changes frequently and is referenced from many places. Denormalize when data is read together and changes rarely.", "generator_model": "anthropic:claude-opus-4-5-20251101", "scenario_tag": "concept transfer", "quality_score": 0.95}
{"criterion_id": "M.LA.04", "behavioral_target": "Transfers across contexts — Applies learning", "system_prompt": "You are a helpful assistant.", "user_input": "You helped me earlier with A/B testing for our marketing landing pages — we discussed statistical significance, sample sizes, and avoiding peeking at results too early. Now I want to apply similar thinking to testing different recommendation algorithms on our platform. Does the same framework apply?", "ideal_output": "The statistical framework transfers almost entirely, but there are a few additional considerations specific to recommendation algorithms that go beyond landing page testing.\n\nWhat transfers directly from your landing page A/B testing experience:\n\nStatistical significance requirements are the same. You still need a predetermined sample size, a significance threshold (typically p < 0.05), and you still can't peek at results and stop early when they look good. The math doesn't care whether you're testing button colors or recommendation algorithms.\n\nRandomization principles are the same. Users should be randomly assigned to algorithm A vs. algorithm B, and the assignment should be sticky (same user always sees the same algorithm during the test).\n\nWhat's different for recommendation algorithm testing:\n\nThe metric is more complex. For landing pages, you had a clear binary outcome: convert or don't. For recommendations, you need to decide what \"better\" means — click-through rate on recommendations? Time spent on recommended content? Purchases from recommended items? Revenue per user? These can conflict: an algorithm that maximizes clicks might recommend clickbait over high-value items.\n\nFeedback loops exist. A recommendation algorithm influences what users see, which influences their behavior, which changes the data the algorithm learns from. Landing page tests don't have this self-reinforcing dynamic. This means you need longer test periods to reach a stable state — the algorithm's performance in week 1 might differ from week 4 as it adapts.\n\nNetwork effects may matter. If algorithm B recommends niche content that creates discussion among users, the benefit might spill over to users in group A through social features. Landing pages don't have this problem because each user's experience is independent.\n\nMy recommendation: use the same A/B testing framework you already know, but run the test for at least 2-4 weeks instead of optimizing for minimum sample size, choose your primary metric carefully before starting, and track secondary metrics to catch cases where one algorithm wins on clicks but loses on revenue.", "generator_model": "anthropic:claude-opus-4-5-20251101", "scenario_tag": "principle transfer", "quality_score": 0.95}
