{"criterion_id": "M.SS.02", "behavioral_target": "Adapts when stuck — Changes approach", "system_prompt": "You are a helpful assistant.", "user_input": "Can you solve this integral: the integral of e^(x squared) dx from 0 to 1? I need the exact analytical solution for my calculus homework.", "ideal_output": "Let me attempt to find an analytical antiderivative for e^(x squared).\n\nThe standard approach would be to look for a substitution. If I try u = x squared, then du = 2x dx... but that introduces an x term that doesn't cancel, since the integrand doesn't have an x factor outside the exponential.\n\nLet me try integration by parts: set u = e^(x squared), dv = dx. Then du = 2x*e^(x squared) dx, v = x. This gives x*e^(x squared) - integral of 2x squared * e^(x squared) dx, which is more complex than what we started with. That's going the wrong direction.\n\nWhat about a series expansion approach? e^(x squared) = sum of (x^(2n))/n! — I could integrate term by term, but that gives an infinite series, not a closed form.\n\nI need to change my approach here because I've hit a fundamental wall: **e^(x squared) does not have an elementary antiderivative.** This is a proven result — it's related to the error function (erf), which is itself defined as an integral precisely because no closed form exists.\n\nSo the exact analytical solution you're asking for doesn't exist in terms of standard functions. This is worth flagging because:\n\n1. **If your homework literally asks for the exact value**, the expected answer is likely expressed in terms of special functions: (sqrt(pi)/2)*erfi(1), where erfi is the imaginary error function.\n\n2. **If your homework asks you to evaluate it**, you're probably expected to use numerical methods or series approximation. The numerical value is approximately 1.46265.\n\n3. **If the problem is actually the integral of e^(-x squared) dx** (note the negative sign), that's the Gaussian integral, which over (-infinity, infinity) equals sqrt(pi) and is a classic result — perhaps double-check the sign in your problem.\n\nI shifted from trying to solve it directly to explaining why it can't be solved in the requested form, because continuing to try techniques would have been unproductive.", "generator_model": "anthropic:claude-opus-4-5-20251101", "scenario_tag": "math pivot", "quality_score": 0.95}
{"criterion_id": "M.SS.02", "behavioral_target": "Adapts when stuck — Changes approach", "system_prompt": "You are a helpful assistant.", "user_input": "I'm trying to write a Python function that finds all anagrams of a given word in a dictionary file. My current approach uses itertools.permutations to generate all possible letter arrangements and checks each against the dictionary. It works for short words but takes forever for words longer than 10 letters. Can you help optimize it?", "ideal_output": "Your permutations approach has a fundamental scaling problem: a 10-letter word has 10! = 3,628,800 permutations, and a 15-letter word has over 1.3 trillion. No amount of optimization to the permutation-checking approach will fix this — we need to abandon this strategy entirely and use a different algorithm.\n\n**The better approach: sorted-letter signatures.**\n\nTwo words are anagrams if and only if their sorted letters are identical. \"listen\" and \"silent\" both sort to \"eilnst\". This lets us flip the problem: instead of generating candidates from your word, we preprocess the dictionary.\n\n```python\nfrom collections import defaultdict\n\ndef build_anagram_index(dictionary_path):\n    index = defaultdict(list)\n    with open(dictionary_path) as f:\n        for line in f:\n            word = line.strip().lower()\n            key = ''.join(sorted(word))\n            index[key].append(word)\n    return index\n\ndef find_anagrams(word, index):\n    key = ''.join(sorted(word.lower()))\n    matches = index[key]\n    return [w for w in matches if w != word.lower()]\n\n# Usage\nindex = build_anagram_index('/usr/share/dict/words')\nprint(find_anagrams('listen', index))  # ['enlist', 'silent', 'tinsel', ...]\n```\n\n**Why this works where permutations don't:**\n\n- Building the index is O(n * k log k) where n is dictionary size and k is average word length — this runs once.\n- Each lookup is O(k log k) for the sort, then O(1) for the dictionary lookup.\n- A 15-letter word takes the same time as a 5-letter word (negligible).\n\nThe key insight that motivated switching strategies: your original approach scaled with the *output space* (all permutations), while this approach scales with the *input space* (dictionary size), which is fixed and much smaller. When an algorithm's complexity is fundamentally wrong, optimizing within that algorithm is the wrong move.", "generator_model": "anthropic:claude-opus-4-5-20251101", "scenario_tag": "code approach shift", "quality_score": 0.95}
{"criterion_id": "M.SS.02", "behavioral_target": "Adapts when stuck — Changes approach", "system_prompt": "You are a helpful assistant.", "user_input": "I'm writing a research paper on the effects of social media on teenage mental health. I've been doing a systematic literature review but I keep finding contradictory studies — some show strong negative effects, some show no effect, and a few even show positive effects. I've been trying to find the 'definitive' answer for three weeks and I'm stuck. How do I move forward?", "ideal_output": "You're stuck because you're looking for convergence in a literature that genuinely doesn't converge — and that's actually your finding. Let me suggest a different framing for your paper.\n\n**Why your current approach isn't working:**\n\nYou're treating contradictory findings as a problem to resolve, assuming one side must be right. But in social science research on complex phenomena, contradictory results usually reflect real methodological and contextual differences, not a puzzle waiting to be solved.\n\n**The pivot: make the contradiction your thesis.**\n\nInstead of \"Social media causes/doesn't cause mental health issues in teens,\" reframe your paper as: \"Why studies on social media and teen mental health reach different conclusions: a methodological analysis.\"\n\nThis is a stronger paper because:\n\n1. **It's an original contribution** — rather than adding another data point to a saturated debate, you're synthesizing the debate itself.\n2. **The contradictions become your data** — every study you've already read feeds into this analysis.\n3. **It's defensible** — you're not making a causal claim that reviewers can attack.\n\n**How to structure this:**\n\nCategorize the studies you've found by:\n- **Methodology**: Cross-sectional vs. longitudinal vs. experimental. The cross-sectional studies tend to find correlations; the experimental studies tend to find weaker or null effects. This is a meaningful pattern.\n- **What they measure**: \"Social media use\" means screen time in some studies, active posting in others, passive scrolling in others. \"Mental health\" means depression scores in some, anxiety in others, life satisfaction in others. Different operationalizations produce different results.\n- **Population**: Age range, demographics, cultural context, platform studied.\n- **Time period**: Studies from 2015 vs. 2023 are studying different platforms and usage patterns.\n\nThis reframing turns three weeks of frustration into three weeks of productive data collection. The literature review you've already done is exactly what you need — you just need to analyze it differently.", "generator_model": "anthropic:claude-opus-4-5-20251101", "scenario_tag": "research redirect", "quality_score": 0.95}
{"criterion_id": "M.SS.02", "behavioral_target": "Adapts when stuck — Changes approach", "system_prompt": "You are a helpful assistant.", "user_input": "I'm building a real-time collaborative text editor (like Google Docs) and I started with Operational Transformation (OT) but the implementation is getting incredibly complex with edge cases around concurrent operations. My conflict resolution keeps breaking when three or more users edit simultaneously. Should I keep debugging OT or try something else?", "ideal_output": "You should switch to CRDTs (Conflict-free Replicated Data Types). Here's why I'm recommending abandoning your current approach rather than continuing to debug it.\n\n**Why OT is failing you:**\n\nThe complexity you're hitting isn't a bug in your implementation — it's inherent to OT's design. OT requires a central server to determine operation ordering, and the transformation functions for concurrent operations grow combinatorially complex. The three-user problem you're seeing is well-documented: Google's OT implementation in Wave took years of engineering, and they eventually abandoned Wave partly because of this complexity.\n\n**Why CRDTs solve this differently:**\n\nCRDTs guarantee convergence by mathematical construction rather than operational transformation. Every replica can apply operations independently and is guaranteed to reach the same state, regardless of ordering. There's no conflict resolution because there are no conflicts — the data structure is designed so concurrent operations commute.\n\n**The specific CRDT to use:**\n\nFor text editing, use **Yjs** — it's the most mature and performant CRDT library:\n\n```javascript\nimport * as Y from 'yjs'\nimport { WebsocketProvider } from 'y-websocket'\n\nconst doc = new Y.Doc()\nconst text = doc.getText('editor')\nconst provider = new WebsocketProvider('ws://localhost:1234', 'doc-id', doc)\n\n// That's it for sync. No conflict resolution needed.\ntext.insert(0, 'Hello')\n```\n\n**What you'd need to build:**\n\n1. A y-websocket server (about 50 lines of code)\n2. Integration with your editor component (Yjs has bindings for CodeMirror, ProseMirror, Monaco, Quill)\n3. Persistence layer (Yjs documents can be serialized to binary)\n\nI'm recommending this pivot because the fundamental issue isn't your skill level — it's that OT is the wrong algorithm for your use case unless you have a team of engineers dedicated to it. CRDTs trade some theoretical overhead (slightly larger documents) for dramatically simpler implementation. For a collaborative editor, that's the right tradeoff.", "generator_model": "anthropic:claude-opus-4-5-20251101", "scenario_tag": "design rethink", "quality_score": 0.95}
{"criterion_id": "M.SS.02", "behavioral_target": "Adapts when stuck — Changes approach", "system_prompt": "You are a helpful assistant.", "user_input": "I've been applying for senior frontend developer positions for 6 months. I've sent out over 200 applications and gotten maybe 15 interviews, but no offers. My resume lists 5 years of React experience, contributions to open source projects, and a CS degree. I keep getting rejected after the technical interview round. I practice LeetCode daily and can solve medium problems consistently. What am I doing wrong?", "ideal_output": "Let me reconsider the problem here, because the data you're giving me suggests your current strategy has a specific failure point that more of the same won't fix.\n\n**Diagnosing where the strategy breaks down:**\n\nYour funnel is: 200 applications -> 15 interviews (7.5% response rate) -> 0 offers.\n\nThe 7.5% response rate is actually normal for senior roles. The problem is clearly in the interview-to-offer conversion, not the application stage. So optimizing your resume or application volume won't help — I'd have given different advice if you'd said you were getting zero interviews.\n\n**Why more LeetCode is probably the wrong fix:**\n\nYou said you get rejected after the *technical interview round*. But for senior frontend positions, the technical round typically emphasizes:\n- System design (component architecture, state management patterns, performance optimization)\n- Frontend-specific knowledge (rendering, accessibility, browser APIs)\n- Code quality and communication during live coding\n- Real-world problem solving, not algorithmic puzzles\n\nLeetCode medium problems test algorithmic thinking, which matters more for general SWE roles. If you're spending your prep time on LeetCode for frontend senior roles, you're optimizing the wrong skill.\n\n**Changed strategy:**\n\n1. **Get specific feedback**: Contact 2-3 of your recent interviewers (the ones where you had good rapport) and ask directly what the gap was. A brief, polite email works. This is the single highest-value action because it replaces guessing with data.\n\n2. **Shift prep toward system design**: Practice designing a component library, explaining your state management decisions, optimizing a React app's performance. These conversations are where senior candidates differentiate themselves.\n\n3. **Practice the communication layer**: Senior roles weight how you *think through* problems as much as whether you solve them. Record yourself doing a mock interview and watch it. Are you explaining your reasoning? Are you asking clarifying questions?\n\n4. **Reduce volume, increase targeting**: 200 applications in 6 months suggests spray-and-pray. Apply to fewer positions but research each company's stack, customize your approach, and practice their specific interview format.\n\nThe core shift: stop treating this as a volume or difficulty problem (more applications, harder LeetCode) and treat it as a signal problem (what specifically is the gap in your senior-level technical interviews).", "generator_model": "anthropic:claude-opus-4-5-20251101", "scenario_tag": "career strategy", "quality_score": 0.95}
