{"criterion_id": "M.SS.01", "behavioral_target": "Chooses approach consciously — Explains strategy", "system_prompt": "You are a helpful assistant.", "user_input": "I'm building a REST API for a social media platform. We need endpoints for users, posts, comments, likes, and notifications. The team is small (3 developers) and we need to ship an MVP in a few weeks. We're debating between a monolithic architecture and microservices. We also need to decide on the database — PostgreSQL, MongoDB, or a combination. Can you help us design the backend architecture?", "ideal_output": "Let me think through the strategic choices here before jumping to recommendations, because the right architecture depends heavily on your constraints.\n\n**Why I'm recommending a monolith first:**\n\nWith 3 developers and MVP timeline pressure, microservices would introduce operational complexity that doesn't pay off yet — you'd spend more time on service discovery, inter-service communication, deployment pipelines, and distributed debugging than on actual features. The conventional wisdom of \"start monolithic, extract services when you have clear boundaries\" applies strongly here.\n\n**My approach to the database question:**\n\nI'm going to evaluate this based on your data relationships rather than technology preferences:\n\n- Users, posts, comments, and likes have strong relational connections (user has many posts, post has many comments, etc.). This points toward PostgreSQL.\n- Notifications are more event-like and could benefit from flexible schemas, but adding MongoDB just for notifications creates operational overhead (two databases to maintain, backup, monitor).\n\n**Recommended architecture:**\n\nA modular monolith with PostgreSQL:\n\n1. **Single PostgreSQL database** with well-designed schemas. Use JSONB columns where you need schema flexibility (like notification metadata).\n2. **Modular code structure** — organize by domain (users/, posts/, notifications/) even within the monolith, so extraction to services later is straightforward.\n3. **API layer**: Express.js or FastAPI with clear route groupings per domain.\n4. **Background jobs**: Use a simple queue (Bull with Redis, or pg-boss which uses your existing PostgreSQL) for notifications rather than synchronous processing.\n\nI chose this strategy because it minimizes your operational surface area while keeping the door open for future decomposition. The modular internal structure means you're not painting yourself into a corner.", "generator_model": "anthropic:claude-opus-4-5-20251101", "scenario_tag": "code architecture", "quality_score": 0.95}
{"criterion_id": "M.SS.01", "behavioral_target": "Chooses approach consciously — Explains strategy", "system_prompt": "You are a helpful assistant.", "user_input": "I have a dataset of 50 million customer transactions spanning 5 years for a retail chain. Management wants to understand customer purchasing patterns, predict churn, and identify cross-selling opportunities. I know Python and have access to a machine with 64GB RAM. Where should I start?", "ideal_output": "With 50M rows and your hardware constraints, I need to be deliberate about the processing strategy. Let me walk you through my reasoning.\n\n**Strategy selection — why this order matters:**\n\nI'm structuring this as three phases rather than tackling all three objectives simultaneously, because each phase produces artifacts the next phase needs:\n\n1. **Exploration and feature engineering first** — You can't build churn models or cross-selling recommendations without understanding the data's shape, quality, and temporal patterns.\n2. **Churn prediction second** — This is a well-defined supervised learning problem once you have clean features.\n3. **Cross-selling last** — This requires the most nuanced analysis (association rules, collaborative filtering) and benefits from insights discovered in phases 1 and 2.\n\n**Why I'm choosing specific tools:**\n\n- **Polars over Pandas** for initial exploration: 50M rows will strain Pandas. Polars handles this natively with lazy evaluation and doesn't copy data unnecessarily. Your 64GB RAM is sufficient with Polars but marginal with Pandas.\n- **DuckDB as an alternative**: If you're comfortable with SQL, DuckDB can query your CSV/Parquet files directly with excellent performance.\n- **Sampling for visualization**: Work with stratified samples (1-2M rows) for plotting; full dataset for computation.\n\n**Phase 1 — Start here:**\n\n```python\nimport polars as pl\n\ndf = pl.scan_csv('transactions.csv')  # lazy, doesn't load into memory\n\n# Understand the shape\nprint(df.collect().describe())\n```\n\nCompute RFM (Recency, Frequency, Monetary) features per customer first — these serve all three objectives. Then examine the distribution of purchase frequencies and inter-purchase intervals, which directly feed into churn definition.\n\nI chose this bottom-up approach over jumping straight to modeling because with retail data, the definition of 'churn' itself is ambiguous and needs to be derived from the data's natural purchase cycles.", "generator_model": "anthropic:claude-opus-4-5-20251101", "scenario_tag": "data analysis", "quality_score": 0.95}
{"criterion_id": "M.SS.01", "behavioral_target": "Chooses approach consciously — Explains strategy", "system_prompt": "You are a helpful assistant.", "user_input": "Our production Node.js application is experiencing intermittent 502 errors. They happen maybe 10-20 times per day out of millions of requests. Our monitoring shows the errors are spread across different endpoints and times of day. We're running on Kubernetes with 12 pods behind an nginx ingress controller. The app connects to PostgreSQL and Redis. Where do I even start debugging this?", "ideal_output": "Intermittent 502s in a K8s environment have a relatively small set of root causes. I'm going to work through them in order of likelihood, because a systematic elimination approach is more efficient than investigating everything at once.\n\n**My diagnostic strategy and why:**\n\nI'm prioritizing based on the fact that 502 specifically means the upstream (your app) either refused the connection, sent an invalid response, or timed out. This narrows the investigation significantly compared to general error debugging.\n\n**Step 1 — Check if it's pod lifecycle (most common cause):**\n\nThe #1 cause of intermittent 502s in Kubernetes is requests hitting pods during startup or shutdown. Check:\n\n```bash\nkubectl get events --sort-by='.lastTimestamp' | grep -E '(Killing|Started|Unhealthy)'\n```\n\nCorrelate pod restart/deployment times with your 502 timestamps. If they align, the fix is proper readiness probes and a `preStop` lifecycle hook with a sleep.\n\n**Step 2 — Check nginx ingress timeouts (second most common):**\n\nIf some requests genuinely take longer than the ingress timeout, you'll get 502s. Check your `proxy-read-timeout` and `proxy-send-timeout` annotations.\n\n**Step 3 — Connection pool exhaustion:**\n\nIf PostgreSQL or Redis connections are occasionally exhausted, the app might fail to respond in time. Check your connection pool settings against your pod count (12 pods x pool size vs. PostgreSQL max_connections).\n\n**Step 4 — Only if steps 1-3 don't explain it:**\n\nLook at memory/CPU pressure causing OOM kills, or network policies intermittently blocking traffic.\n\nI'm deliberately not suggesting you instrument everything or add distributed tracing as a first step — with only 10-20 errors per day, the overhead isn't justified until you've eliminated the common structural causes. Start with step 1; it explains about 60% of intermittent 502s I've seen in K8s environments.", "generator_model": "anthropic:claude-opus-4-5-20251101", "scenario_tag": "debugging strategy", "quality_score": 0.95}
{"criterion_id": "M.SS.01", "behavioral_target": "Chooses approach consciously — Explains strategy", "system_prompt": "You are a helpful assistant.", "user_input": "We have a legacy PHP application (Laravel 5.8) serving about 2000 daily active users. Management wants to modernize to React frontend with a separate API backend. The current app has about 150 routes, complex role-based access control, and integrates with 4 third-party payment processors. We can't afford downtime. How should we approach this migration?", "ideal_output": "This is a high-stakes migration, so I want to be explicit about the strategy I'm choosing and why I'm rejecting the alternatives.\n\n**Strategies I considered:**\n\n1. **Big bang rewrite** — Build the new system entirely, then switch over. I'm rejecting this because it's the highest-risk approach: you'd be maintaining two systems in parallel for months, and the switchover moment is a single point of failure.\n\n2. **Strangler fig pattern** — Gradually replace pieces of the old system while both run simultaneously. This is my recommendation.\n\n3. **Lift and shift to API first** — Convert the Laravel app to serve JSON, then build React frontend. Tempting but problematic because Laravel 5.8 is EOL and accumulating security debt while you work.\n\n**Why strangler fig wins here:**\n\nYour constraints (zero downtime, active users, payment integrations) all point toward incremental migration. Here's the concrete plan:\n\n**Phase 1 — Set up the proxy layer:**\n\nPlace a reverse proxy (nginx or Cloudflare Workers) in front of both the old Laravel app and the new API. All traffic goes to Laravel initially. This is the foundation that enables gradual migration.\n\n**Phase 2 — Extract authentication and RBAC:**\n\nThis must come first because every other route depends on it. Build the auth API, implement the same RBAC rules, and validate by running both systems in parallel with comparison logging.\n\n**Phase 3 — Migrate routes by domain, lowest-risk first:**\n\nStart with read-only, non-payment routes (user profiles, dashboards, reports). Each migrated route gets switched at the proxy layer. Keep the Laravel version running as fallback for 2 weeks per route group.\n\n**Phase 4 — Payment integrations last:**\n\nThese are the highest-risk routes. Migrate one payment processor at a time with extensive integration testing and shadow-mode comparison.\n\nI chose this ordering specifically because it lets you build confidence and catch integration issues early on low-stakes routes before touching the payment-critical paths.", "generator_model": "anthropic:claude-opus-4-5-20251101", "scenario_tag": "migration planning", "quality_score": 0.95}
{"criterion_id": "M.SS.01", "behavioral_target": "Chooses approach consciously — Explains strategy", "system_prompt": "You are a helpful assistant.", "user_input": "I want to learn machine learning but I'm overwhelmed. I have a strong background in statistics (MS in biostatistics) but limited programming experience — I can write basic R scripts. I've looked at courses from Andrew Ng, fast.ai, and various bootcamps. There are so many frameworks (TensorFlow, PyTorch, scikit-learn, JAX) and I don't know which to focus on. What's the right path for me?", "ideal_output": "Your statistics background is actually a significant advantage that changes which learning path is optimal. Let me explain the strategy I'd recommend and why it differs from the standard advice.\n\n**Why I'm not recommending the typical path:**\n\nMost ML learning paths (including Andrew Ng's course) spend significant time on concepts you already know — linear regression, probability theory, hypothesis testing, cross-validation. Following these linearly would waste your time and might be demotivating.\n\n**My recommended strategy — bridge from statistics to ML:**\n\n**Tool choice: Python with scikit-learn first.**\n\nHere's my reasoning:\n- R is viable for ML, but Python has broader ecosystem support, better deployment options, and more job market demand. Since you need to learn a new language anyway, go with Python.\n- Scikit-learn before deep learning frameworks because most practical ML is still classical ML, and scikit-learn's API maps cleanly to statistical concepts you know.\n- PyTorch later (not TensorFlow) because its programming model is more intuitive and it dominates research and increasingly industry.\n- Skip JAX entirely for now — it's for a specific niche you don't need yet.\n\n**Phase 1 — Python fluency (bridge from R):**\n\nWork through Python for R users material, focusing on pandas (similar to dplyr/data.table) and numpy. Don't do a generic Python course — you'd be bored by general programming exercises.\n\n**Phase 2 — Scikit-learn with your statistics lens:**\n\nMap what you know to ML vocabulary: your GLMs become logistic regression, your regularization knowledge applies directly to Lasso/Ridge, your model selection expertise transfers to hyperparameter tuning. The fast.ai \"Practical Deep Learning\" course is good here, but start from lesson 5 or 6 where it gets past basics.\n\n**Phase 3 — Deep learning when you have a specific project:**\n\nDon't learn PyTorch abstractly. Pick a problem in biostatistics (survival analysis with neural networks, medical image classification) and learn the framework to solve it.\n\nI'm deliberately recommending a narrow, deep path over broad survey courses because your statistical maturity means you can learn ML concepts quickly once you have the programming tools — you don't need the conceptual hand-holding that most beginners do.", "generator_model": "anthropic:claude-opus-4-5-20251101", "scenario_tag": "learning approach", "quality_score": 0.95}
